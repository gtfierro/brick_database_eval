{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_ITERATIONS = 10\n",
    "def avg(l):\n",
    "    return float(sum(l))/(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query0_sparql = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX brick: <http://buildsys.org/ontologies/Brick#> \n",
    "PREFIX bf: <http://buildsys.org/ontologies/BrickFrame#> \n",
    "SELECT DISTINCT ?vav\n",
    "WHERE {\n",
    "    ?vav rdf:type brick:VAV .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "query0_hod = \"\"\"\n",
    "SELECT ?vav\n",
    "WHERE {\n",
    "    ?vav rdf:type brick:VAV .\n",
    "};\n",
    "\"\"\"\n",
    "\n",
    "query0_rdf3x = query0_sparql\n",
    "\n",
    "query1_sparql = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX brick: <http://buildsys.org/ontologies/Brick#> \n",
    "PREFIX bf: <http://buildsys.org/ontologies/BrickFrame#> \n",
    "SELECT DISTINCT ?sensor ?room\n",
    "WHERE {\n",
    "\n",
    "    ?sensor rdf:type/rdfs:subClassOf* brick:Zone_Temperature_Sensor .\n",
    "    ?room rdf:type brick:Room .\n",
    "    ?vav rdf:type brick:VAV .\n",
    "    ?zone rdf:type brick:HVAC_Zone .\n",
    "\n",
    "    ?vav bf:feeds+ ?zone .\n",
    "    ?zone bf:hasPart ?room .\n",
    "\n",
    "    {?sensor bf:isPointOf ?vav }\n",
    "    UNION\n",
    "    {?sensor bf:isPointOf ?room }\n",
    "}\n",
    "\"\"\"\n",
    "query1_hod = \"\"\"\n",
    "SELECT ?sensor ?room\n",
    "WHERE {\n",
    "    ?sensor rdf:type/rdfs:subClassOf* brick:Zone_Temperature_Sensor .\n",
    "    ?room rdf:type brick:Room .\n",
    "    ?vav rdf:type brick:VAV .\n",
    "    ?zone rdf:type brick:HVAC_Zone .\n",
    "\n",
    "    ?vav bf:feeds+ ?zone .\n",
    "    ?zone bf:hasPart ?room .\n",
    "\n",
    "    { ?sensor bf:isPointOf ?vav .\n",
    "    OR\n",
    "    ?sensor bf:isPointOf ?room . }\n",
    "};\n",
    "\"\"\"\n",
    "query1_rdf3x = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX brick: <http://buildsys.org/ontologies/Brick#> \n",
    "PREFIX bf: <http://buildsys.org/ontologies/BrickFrame#> \n",
    "SELECT DISTINCT ?sensor ?room\n",
    "WHERE {\n",
    "\n",
    "    ?sensor rdf:type brick:ZoneTemperatureSensor .\n",
    "    ?room rdf:type brick:Room .\n",
    "    ?vav rdf:type brick:VAV .\n",
    "    ?zone rdf:type brick:HVACZone .\n",
    "\n",
    "    ?vav bf:feeds ?zone .\n",
    "    ?zone bf:hasPart ?room .\n",
    "    ?sensor bf:isPointOf ?vav .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "query2_sparql = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX brick: <http://buildsys.org/ontologies/Brick#> \n",
    "PREFIX bf: <http://buildsys.org/ontologies/BrickFrame#> \n",
    "SELECT ?vlv_cmd ?vav\n",
    "WHERE {\n",
    "    {\n",
    "      { ?vlv_cmd rdf:type brick:Reheat_Valve_Command }\n",
    "      UNION\n",
    "      { ?vlv_cmd rdf:type brick:Cooling_Valve_Command }\n",
    "    }\n",
    "    ?vav rdf:type brick:VAV .\n",
    "    ?vav bf:hasPoint+ ?vlv_cmd .\n",
    "}\n",
    "\"\"\"\n",
    "query2_hod = \"\"\"\n",
    "SELECT ?vlv_cmd ?vav\n",
    "WHERE {\n",
    "    {\n",
    "      { \n",
    "      ?vlv_cmd rdf:type brick:Reheat_Valve_Command .\n",
    "      OR\n",
    "      ?vlv_cmd rdf:type brick:Cooling_Valve_Command .\n",
    "      }\n",
    "    }\n",
    "    ?vav rdf:type brick:VAV .\n",
    "    ?vav bf:hasPoint+ ?vlv_cmd .\n",
    "};\n",
    "\"\"\"\n",
    "\n",
    "query3_sparql = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX brick: <http://buildsys.org/ontologies/Brick#> \n",
    "PREFIX bf: <http://buildsys.org/ontologies/BrickFrame#> \n",
    "SELECT ?floor ?room ?zone\n",
    "WHERE {\n",
    "    ?floor rdf:type brick:Floor .\n",
    "    ?room rdf:type brick:Room .\n",
    "    ?zone rdf:type brick:HVAC_Zone .\n",
    "\n",
    "    ?room bf:isPartOf+ ?floor .\n",
    "    ?room bf:isPartOf+ ?zone .\n",
    "}\n",
    "\"\"\"\n",
    "query3_hod = \"\"\"\n",
    "SELECT ?floor ?room ?zone\n",
    "WHERE {\n",
    "    ?floor rdf:type brick:Floor .\n",
    "    ?room rdf:type brick:Room .\n",
    "    ?zone rdf:type brick:HVAC_Zone .\n",
    "\n",
    "    ?room bf:isPartOf+ ?floor .\n",
    "    ?room bf:isPartOf+ ?zone .\n",
    "};\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(func, show_first=False, iterations=NUM_ITERATIONS):\n",
    "    query_times = []\n",
    "    for i in range(iterations):\n",
    "        t1 = time.time()*1000\n",
    "        resp = func()\n",
    "        t2 = time.time()*1000\n",
    "        if resp is None: break\n",
    "        if i == 0 and show_first: print resp.content\n",
    "        query_times.append(t2-t1)\n",
    "        print i, '{0:.2f}'.format(t2-t1)\n",
    "        time.sleep(.5)\n",
    "    query_avg = avg(query_times)\n",
    "    print \"Took {0:.2f}ms\".format(query_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hod Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hod Configs\n",
    "HOD_SERVER = \"http://localhost:47808/query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run hod\n",
    "!cd hod; ./runserver.sh ; cd ..\n",
    "#!cd hod; docker kill hod ; docker rm hod; docker run -d --name hod -p47808:47808 gtfierro/hod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## query 0\n",
    "def hod_query_0():\n",
    "    resp = requests.post(HOD_SERVER, data=query0_hod)\n",
    "    if not resp.ok:\n",
    "        print resp, resp.reason\n",
    "        return None\n",
    "    return resp\n",
    "\n",
    "run(hod_query_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## query 1https://github.com/neo4j-contrib/sparql-plugin\n",
    "def hod_query_1():\n",
    "    resp = requests.post(HOD_SERVER, data=query1_hod)\n",
    "    if not resp.ok:\n",
    "        print resp, resp.reason\n",
    "        return None\n",
    "    return resp\n",
    "\n",
    "run(hod_query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## query 2\n",
    "def hod_query_2():\n",
    "    resp = requests.post(HOD_SERVER, data=query2_hod)\n",
    "    if not resp.ok:\n",
    "        print resp, resp.reason\n",
    "        return None\n",
    "    return resp\n",
    "run(hod_query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## query 3\n",
    "def hod_query_3():\n",
    "    resp = requests.post(HOD_SERVER, data=query3_hod)\n",
    "    if not resp.ok:\n",
    "        print resp, resp.reason\n",
    "        return None\n",
    "    return resp\n",
    "run(hod_query_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuseki Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fuseki Configs\n",
    "FUSEKI_SERVER = \"http://localhost:3031/berkeley/query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker pull gtfierro/fuseki\n",
      "Using default tag: latest\n",
      "latest: Pulling from gtfierro/fuseki\n",
      "\u001b[0BDigest: sha256:258ffe22f17a04e7792b8fedcb44f4b5b62df627958048f463d99ad26304b7d2\n",
      "Status: Image is up to date for gtfierro/fuseki:latest\n",
      "+ docker kill fuseki\n",
      "Error response from daemon: Cannot kill container fuseki: Container ecdb3b16a2ed635f10b8a492bc2c6652ea1bb59937bb38104565219aa7974324 is not running\n",
      "+ docker rm fuseki\n",
      "fuseki\n",
      "+ docker run -d --name fuseki -p3031:3030 gtfierro/fuseki\n",
      "0a84b11090cdd546a3e112c698c8b528a7b3c37568caba1886f350855c77e714\n"
     ]
    }
   ],
   "source": [
    "!cd fuseki; ./runserver.sh ; cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 22.97\n",
      "1 17.57\n",
      "2 15.17\n",
      "3 11.07\n",
      "4 14.47\n",
      "5 12.59\n",
      "6 12.68\n",
      "7 10.90\n",
      "8 15.37\n",
      "9 13.51\n",
      "Took 14.63ms\n"
     ]
    }
   ],
   "source": [
    "## query 0\n",
    "def fuseki_query_0():\n",
    "    resp = requests.post(FUSEKI_SERVER, params={'query':query0_sparql})\n",
    "    if not resp.ok:\n",
    "        print resp, resp.reason\n",
    "        return None\n",
    "    return resp\n",
    "run(fuseki_query_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## query 1\n",
    "def fuseki_query_1(iterations=1):\n",
    "    resp = requests.post(FUSEKI_SERVER, params={'query':query1_sparql})\n",
    "    if not resp.ok:\n",
    "        print resp, resp.reason\n",
    "        return None\n",
    "    return resp\n",
    "run(fuseki_query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## query 2\n",
    "def fuseki_query_2(iterations=1):\n",
    "    resp = requests.post(FUSEKI_SERVER, params={'query':query2_sparql})\n",
    "    if not resp.ok:\n",
    "        print resp, resp.reason\n",
    "        return None\n",
    "    return resp\n",
    "run(fuseki_query_2, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Alegrograph Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ALEGRO_SERVER = \"http://localhost:10035/repositories/berkeley/sparql\"\n",
    "auth = HTTPBasicAuth('root','asdfasdf')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cd alegrograph; ./runserver.sh ; cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def alegro_query_0():\n",
    "    resp = requests.post(ALEGRO_SERVER, data={'query': query0_sparql}, auth=auth)\n",
    "    if not resp.ok:\n",
    "        print resp, resp.reason\n",
    "        return None\n",
    "    return resp\n",
    "run(alegro_query_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def alegro_query_1():\n",
    "    resp = requests.post(ALEGRO_SERVER, data={'query': query1_sparql}, auth=auth)\n",
    "    if not resp.ok:\n",
    "        print resp, resp.reason\n",
    "        return None\n",
    "    return resp\n",
    "run(alegro_query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def alegro_query_2():\n",
    "    resp = requests.post(ALEGRO_SERVER, data={'query': query2_sparql}, auth=auth)\n",
    "    if not resp.ok:\n",
    "        print resp, resp.reason\n",
    "        return None\n",
    "    return resp\n",
    "run(alegro_query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def alegro_query_3():\n",
    "    resp = requests.post(ALEGRO_SERVER, data={'query': query3_sparql}, auth=auth)\n",
    "    if not resp.ok:\n",
    "        print resp, resp.reason\n",
    "        return None\n",
    "    return resp\n",
    "run(alegro_query_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## RDF3X Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RDF3X_SERVER = \"http://localhost:8080/bar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker pull gtfierro/rdf3x\n",
      "Using default tag: latest\n",
      "latest: Pulling from gtfierro/rdf3x\n",
      "\u001b[0BDigest: sha256:d2e7690aaf506da2a85b69c4370e9809f7d3a94c53bb99ffea60ed06a29a7ca6\n",
      "Status: Image is up to date for gtfierro/rdf3x:latest\n",
      "+ docker kill rdf3x\n",
      "rdf3x\n",
      "+ docker rm rdf3x\n",
      "rdf3x\n",
      "+ docker run -d --name rdf3x -p8080:8080 gtfierro/rdf3x\n",
      "5374b0e1a94ad06cf7720ac48a17fa6251735f76de149037686de803964f277c\n"
     ]
    }
   ],
   "source": [
    "!cd rdf3x; ./runserver.sh ; cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.16\n",
      "1 9.82\n",
      "2 8.18\n",
      "3 9.31\n",
      "4 6.40\n",
      "5 6.62\n",
      "6 6.12\n",
      "7 9.02\n",
      "8 6.97\n",
      "9 8.83\n",
      "Took 8.04ms\n"
     ]
    }
   ],
   "source": [
    "def rdf3x_query_0():\n",
    "    resp = requests.post(RDF3X_SERVER, data=query0_rdf3x)\n",
    "    if not resp.ok:\n",
    "        print resp, resp.reason\n",
    "        return None\n",
    "    return resp\n",
    "run(rdf3x_query_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<empty result>\n",
      "\n",
      "0 5.66\n",
      "<empty result>\n",
      "\n",
      "1 6.57\n",
      "<empty result>\n",
      "\n",
      "2 6.22\n",
      "<empty result>\n",
      "\n",
      "3 6.04\n",
      "<empty result>\n",
      "\n",
      "4 5.83\n",
      "<empty result>\n",
      "\n",
      "5 6.36\n",
      "<empty result>\n",
      "\n",
      "6 5.59\n",
      "<empty result>\n",
      "\n",
      "7 6.30\n",
      "<empty result>\n",
      "\n",
      "8 7.27\n",
      "<empty result>\n",
      "\n",
      "9 5.69\n",
      "Took 6.15ms\n"
     ]
    }
   ],
   "source": [
    "def rdf3x_query_1():\n",
    "    resp = requests.post(RDF3X_SERVER, data=query1_rdf3x)\n",
    "    if not resp.ok:\n",
    "        print resp, resp.reason\n",
    "        return None\n",
    "    print resp.content\n",
    "    return resp\n",
    "run(rdf3x_query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
